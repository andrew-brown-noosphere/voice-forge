#!/usr/bin/env python3
"""
Fixed test script for the Enhanced Hybrid RAG implementation.
This version properly handles database transactions to avoid foreign key violations.
"""

import asyncio
import sys
import os
import time
from typing import Dict, Any, List
from datetime import datetime

# Add the backend directory to the Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from sqlalchemy import create_engine, text
from database.session import DATABASE_URL, get_db_session
from services.enhanced_rag_service import (
    create_hybrid_rag_service,
    KeywordSearchStrategy,
    CrossEncoderReranker,
    SearchResult
)

import logging

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

class HybridRAGTester:
    """Test suite for hybrid RAG implementation with proper transaction handling."""
    
    def __init__(self):
        self.db_session = None
        self.test_org_id = "test_org_hybrid_rag"
        
    async def setup(self):
        """Set up test environment."""
        try:
            self.db_session = get_db_session()
            logger.info("‚úÖ Database connection established")
            
            # Check if we have test data
            await self._check_test_data()
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Setup failed: {e}")
            return False
    
    async def teardown(self):
        """Clean up test environment."""
        if self.db_session:
            try:
                self.db_session.close()
                logger.info("‚úÖ Database connection closed")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error closing database: {e}")
    
    async def _check_test_data(self):
        """Check if we have sufficient test data."""
        try:
            # Check for content chunks
            chunk_query = text("""
                SELECT COUNT(*) as chunk_count
                FROM content_chunks cc
                WHERE cc.org_id = :org_id
            """)
            
            result = self.db_session.execute(chunk_query, {"org_id": self.test_org_id})
            chunk_count = result.scalar() or 0
            
            logger.info(f"Found {chunk_count} content chunks for testing")
            
            if chunk_count < 3:
                logger.warning("‚ö†Ô∏è Insufficient test data. Creating sample data...")
                await self._create_sample_data()
            
        except Exception as e:
            logger.error(f"‚ùå Failed to check test data: {e}")
            # Don't raise here - we'll try to work with existing data
    
    async def _create_sample_data(self):
        """Create sample test data with proper transaction handling."""
        try:
            logger.info("Creating test crawl session...")
            
            # Step 1: Create crawl session
            crawl_id = "test_crawl_hybrid_rag"
            insert_crawl = text("""
                INSERT INTO crawls (id, org_id, domain, state, start_time, config, pages_crawled, pages_discovered, pages_failed, current_depth, content_extracted)
                VALUES (:id, :org_id, :domain, :state, :start_time, :config, 0, 0, 0, 0, 3)
                ON CONFLICT (id) DO NOTHING
            """)
            
            self.db_session.execute(insert_crawl, {
                "id": crawl_id,
                "org_id": self.test_org_id,
                "domain": "test.example.com",
                "state": "completed",
                "start_time": datetime.utcnow(),
                "config": '{"max_depth": 3, "max_pages": 10}'
            })
            
            # COMMIT after crawl creation
            self.db_session.commit()
            logger.info("‚úÖ Test crawl session created and committed")
            
            # Step 2: Create content records
            logger.info("Creating test content records...")
            
            sample_contents = [
                {
                    "id": "content_hybrid_1",
                    "org_id": self.test_org_id,
                    "url": "https://test.example.com/ml-guide",
                    "domain": "test.example.com",
                    "crawl_id": crawl_id,
                    "text": "Complete guide to machine learning and artificial intelligence applications",
                    "content_type": "article",
                    "title": "Machine Learning Guide"
                },
                {
                    "id": "content_hybrid_2", 
                    "org_id": self.test_org_id,
                    "url": "https://test.example.com/python-tutorial",
                    "domain": "test.example.com",
                    "crawl_id": crawl_id,
                    "text": "Python programming tutorial for data science and machine learning projects",
                    "content_type": "tutorial",
                    "title": "Python Data Science Tutorial"
                },
                {
                    "id": "content_hybrid_3",
                    "org_id": self.test_org_id,
                    "url": "https://test.example.com/database-optimization",
                    "domain": "test.example.com", 
                    "crawl_id": crawl_id,
                    "text": "Database optimization techniques and performance tuning best practices",
                    "content_type": "guide",
                    "title": "Database Performance Guide"
                }
            ]
            
            for content in sample_contents:
                insert_content = text("""
                    INSERT INTO contents (id, org_id, url, domain, crawl_id, extracted_at, text, content_type, title, is_processed)
                    VALUES (:id, :org_id, :url, :domain, :crawl_id, :extracted_at, :text, :content_type, :title, true)
                    ON CONFLICT (id) DO NOTHING
                """)
                
                content["extracted_at"] = datetime.utcnow()
                self.db_session.execute(insert_content, content)
            
            # COMMIT after content creation
            self.db_session.commit()
            logger.info("‚úÖ Test content records created and committed")
            
            # Step 3: Verify content records exist before creating chunks
            verify_query = text("""
                SELECT id FROM contents 
                WHERE org_id = :org_id AND crawl_id = :crawl_id
            """)
            
            result = self.db_session.execute(verify_query, {
                "org_id": self.test_org_id,
                "crawl_id": crawl_id
            })
            
            existing_content_ids = [row.id for row in result.fetchall()]
            logger.info(f"‚úÖ Verified {len(existing_content_ids)} content records exist: {existing_content_ids}")
            
            # Step 4: Create content chunks
            logger.info("Creating test content chunks...")
            
            sample_chunks = [
                {
                    "id": "chunk_hybrid_1",
                    "org_id": self.test_org_id,
                    "content_id": "content_hybrid_1", 
                    "chunk_index": 0,
                    "text": "Machine learning and artificial intelligence are transforming how we build software applications and analyze data.",
                    "start_char": 0,
                    "end_char": 100
                },
                {
                    "id": "chunk_hybrid_2",
                    "org_id": self.test_org_id,
                    "content_id": "content_hybrid_2",
                    "chunk_index": 0, 
                    "text": "Python programming language is widely used for data science, machine learning, and web development projects.",
                    "start_char": 0,
                    "end_char": 100
                },
                {
                    "id": "chunk_hybrid_3",
                    "org_id": self.test_org_id,
                    "content_id": "content_hybrid_3",
                    "chunk_index": 0,
                    "text": "Database optimization techniques include indexing, query optimization, and proper schema design for performance.",
                    "start_char": 0,
                    "end_char": 100
                }
            ]
            
            for chunk in sample_chunks:
                # Verify the content_id exists before inserting chunk
                if chunk["content_id"] in existing_content_ids:
                    insert_chunk = text("""
                        INSERT INTO content_chunks (id, org_id, content_id, chunk_index, text, start_char, end_char)
                        VALUES (:id, :org_id, :content_id, :chunk_index, :text, :start_char, :end_char)
                        ON CONFLICT (id) DO NOTHING
                    """)
                    
                    self.db_session.execute(insert_chunk, chunk)
                    logger.info(f"  ‚úÖ Created chunk for content {chunk['content_id']}")
                else:
                    logger.warning(f"  ‚ö†Ô∏è Skipping chunk for missing content {chunk['content_id']}")
            
            # FINAL COMMIT
            self.db_session.commit()
            logger.info("‚úÖ Sample test data created successfully with proper transactions")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to create sample data: {e}")
            self.db_session.rollback()
            # Don't raise - let tests continue with existing data
    
    async def test_database_basics(self):
        """Test basic database functionality."""
        logger.info("üîç Testing database basics...")
        
        try:
            # Test connection
            result = self.db_session.execute(text("SELECT 1"))
            if result.scalar() != 1:
                return False
                
            # Check tables exist
            tables_query = text("""
                SELECT table_name FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name IN ('content_chunks', 'contents', 'crawls')
            """)
            
            result = self.db_session.execute(tables_query)
            tables = [row.table_name for row in result.fetchall()]
            
            logger.info(f"‚úÖ Found required tables: {tables}")
            
            return len(tables) >= 3
            
        except Exception as e:
            logger.error(f"‚ùå Database basics test failed: {e}")
            return False
    
    async def test_keyword_search(self):
        """Test keyword search strategy."""
        logger.info("üîç Testing keyword search strategy...")
        
        try:
            strategy = KeywordSearchStrategy(self.db_session)
            
            # Find any org with data for testing
            data_query = text("""
                SELECT org_id, COUNT(*) as chunk_count
                FROM content_chunks 
                WHERE text IS NOT NULL AND LENGTH(text) > 10
                GROUP BY org_id
                ORDER BY chunk_count DESC
                LIMIT 1
            """)
            
            result = self.db_session.execute(data_query)
            data_row = result.fetchone()
            
            if not data_row:
                logger.warning("‚ö†Ô∏è No content chunks found - creating test data failed")
                return False
            
            test_org = data_row.org_id
            logger.info(f"Testing with org_id: {test_org} ({data_row.chunk_count} chunks)")
            
            # Test search
            results = await strategy.search(
                query="machine learning programming",
                limit=10,
                org_id=test_org
            )
            
            logger.info(f"‚úÖ Keyword search returned {len(results)} results")
            
            if results:
                for i, result in enumerate(results[:2]):
                    logger.info(f"  Result {i+1}: Score={result.original_score:.3f}")
                    logger.info(f"    Content: {result.content[:80]}...")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Keyword search test failed: {e}")
            return False
    
    async def test_cross_encoder_reranker(self):
        """Test cross-encoder reranking."""
        logger.info("üîç Testing cross-encoder reranker...")
        
        try:
            reranker = CrossEncoderReranker()
            
            # Create sample search results
            sample_results = [
                SearchResult(
                    content="Machine learning algorithms are used to analyze large datasets and make predictions",
                    metadata={"test": True},
                    original_score=0.8,
                    search_type="test"
                ),
                SearchResult(
                    content="Python programming offers excellent libraries for data science and web development",
                    metadata={"test": True}, 
                    original_score=0.6,
                    search_type="test"
                )
            ]
            
            # Test reranking
            reranked = await reranker.rerank("machine learning python", sample_results)
            
            logger.info(f"‚úÖ Reranked {len(reranked)} results")
            
            for i, result in enumerate(reranked):
                rerank_score = result.rerank_score or 0
                logger.info(f"  Result {i+1}: Original={result.original_score:.3f}, Rerank={rerank_score:.3f}")
            
            return len(reranked) > 0
            
        except Exception as e:
            logger.error(f"‚ùå Cross-encoder reranker test failed: {e}")
            return False
    
    async def test_hybrid_service(self):
        """Test the complete hybrid RAG service."""
        logger.info("üîç Testing hybrid RAG service...")
        
        try:
            # Find an org with data
            data_query = text("""
                SELECT org_id, COUNT(*) as chunk_count
                FROM content_chunks 
                WHERE text IS NOT NULL
                GROUP BY org_id
                ORDER BY chunk_count DESC
                LIMIT 1
            """)
            
            result = self.db_session.execute(data_query)
            data_row = result.fetchone()
            
            if not data_row:
                logger.warning("‚ö†Ô∏è No content chunks found for hybrid service test")
                return False
            
            test_org = data_row.org_id
            
            # Create hybrid service
            hybrid_service = create_hybrid_rag_service(self.db_session, vector_service=None)
            
            # Test keyword strategy (most likely to work)
            result = await hybrid_service.retrieve_and_rank(
                query="programming development",
                strategy="keyword",
                top_k=5,
                org_id=test_org
            )
            
            logger.info(f"‚úÖ Hybrid service returned {len(result['results'])} results")
            logger.info(f"‚úÖ Retrieval stats: {result['retrieval_stats']}")
            
            return len(result['results']) >= 0  # Success if no errors
            
        except Exception as e:
            logger.error(f"‚ùå Hybrid service test failed: {e}")
            return False
    
    async def run_all_tests(self):
        """Run all tests and return summary."""
        logger.info("üöÄ Starting hybrid RAG test suite...")
        
        test_results = {}
        
        try:
            setup_success = await self.setup()
            if not setup_success:
                logger.error("‚ùå Setup failed - aborting tests")
                return False
            
            # Run individual tests
            tests = [
                ("Database Basics", self.test_database_basics),
                ("Keyword Search", self.test_keyword_search),
                ("Cross-Encoder Reranker", self.test_cross_encoder_reranker),
                ("Hybrid Service", self.test_hybrid_service)
            ]
            
            for test_name, test_func in tests:
                logger.info(f"\n{'='*50}")
                logger.info(f"Running test: {test_name}")
                logger.info(f"{'='*50}")
                
                start_time = time.time()
                success = await test_func()
                end_time = time.time()
                
                test_results[test_name] = {
                    "success": success,
                    "duration": round(end_time - start_time, 2)
                }
                
                status = "‚úÖ PASSED" if success else "‚ùå FAILED"
                logger.info(f"{status} - {test_name} ({test_results[test_name]['duration']}s)")
            
        except Exception as e:
            logger.error(f"‚ùå Test suite failed: {e}")
            test_results["FATAL_ERROR"] = str(e)
        
        finally:
            await self.teardown()
        
        # Print summary
        logger.info(f"\n{'='*60}")
        logger.info("TEST SUMMARY")
        logger.info(f"{'='*60}")
        
        passed = sum(1 for result in test_results.values() if isinstance(result, dict) and result.get("success"))
        total = len([r for r in test_results.values() if isinstance(r, dict)])
        
        logger.info(f"Tests passed: {passed}/{total}")
        
        for test_name, result in test_results.items():
            if isinstance(result, dict):
                status = "‚úÖ PASSED" if result["success"] else "‚ùå FAILED"
                logger.info(f"  {status} {test_name} ({result['duration']}s)")
            else:
                logger.info(f"  ‚ùå FATAL {test_name}: {result}")
        
        if passed >= total * 0.75:  # 75% success rate is good
            logger.info("\nüéâ Hybrid RAG system is working!")
            logger.info("\nüöÄ Next steps:")
            logger.info("1. Start your FastAPI backend")
            logger.info("2. Test the API: curl -X GET 'http://localhost:8000/api/rag/strategies'")
            logger.info("3. Try hybrid search with your authentication")
            return True
        else:
            logger.info("\n‚ö†Ô∏è Some tests failed, but system may still be functional")
            logger.info("Try starting your backend and testing the API endpoints")
            return False

async def main():
    """Main test runner."""
    tester = HybridRAGTester()
    success = await tester.run_all_tests()
    return 0 if success else 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
